#!/usr/bin/env python3
"""
consolidate_tags.py
-------------------
One-time script to consolidate tags across all YAML metadata files.

Reads a mapping file (JSON) defining old_tag → new_tag transformations,
applies them to all YAML files, deduplicates within each file, and writes
back using the project's YAMLFormatter for consistent formatting.

Usage:
    # Dry run (report changes without writing):
    python scripts/consolidate_tags.py --dry-run

    # Apply changes:
    python scripts/consolidate_tags.py

    # Generate mapping first if needed:
    python scripts/build_tag_mapping.py

Dependencies:
    - scripts/tag_mapping.json (generated by build_tag_mapping.py)
    - dev.utils.yaml_formatter.YAMLFormatter
"""
# --- Annotations ---
from __future__ import annotations

# --- Standard library imports ---
import argparse
import json
import sys
from pathlib import Path
from typing import Dict, List, Tuple

# --- Third-party imports ---
import yaml

# --- Local imports ---
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
from dev.utils.yaml_formatter import YAMLFormatter


# --- Constants ---
PROJECT_ROOT = Path(__file__).resolve().parent.parent
METADATA_DIR = PROJECT_ROOT / "data" / "metadata" / "journal"
MAPPING_FILE = PROJECT_ROOT / "scripts" / "tag_mapping.json"


def load_mapping(mapping_path: Path) -> Dict[str, str]:
    """
    Load the tag mapping from a JSON file.

    Args:
        mapping_path: Path to the JSON mapping file

    Returns:
        Dictionary mapping old tag strings to new tag strings
    """
    with open(mapping_path, encoding="utf-8") as f:
        return json.load(f)


def apply_mapping(tags: List[str], mapping: Dict[str, str]) -> Tuple[List[str], int, int, int]:
    """
    Apply tag mapping to a list of tags, deduplicating the result.

    Preserves order (first occurrence wins for deduplication).
    Filters out tags mapped to empty string (deletions).

    Args:
        tags: Original list of tags
        mapping: Old-to-new tag mapping (empty string means delete)

    Returns:
        Tuple of (new_tags, rename_count, delete_count, dedup_count)
    """
    renamed = 0
    deleted = 0
    new_tags = []
    seen = set()

    for tag in tags:
        new_tag = mapping.get(tag, tag)

        # Handle deletions (mapped to empty string)
        if new_tag == "":
            deleted += 1
            continue

        if new_tag != tag:
            renamed += 1

        # Deduplicate (case-sensitive — canonical tags are already normalized)
        if new_tag not in seen:
            new_tags.append(new_tag)
            seen.add(new_tag)

    deduped = len(tags) - len(new_tags) - deleted
    return new_tags, renamed, deleted, deduped


def process_file(
    file_path: Path,
    mapping: Dict[str, str],
    formatter: YAMLFormatter,
    dry_run: bool = False,
) -> Tuple[int, int, int, bool]:
    """
    Process a single YAML file: apply tag mapping, deduplicate, write back.

    Args:
        file_path: Path to the YAML file
        mapping: Tag mapping dictionary
        formatter: YAMLFormatter instance for output
        dry_run: If True, don't write changes

    Returns:
        Tuple of (renames, deletes, dedupes, changed)
    """
    with open(file_path, encoding="utf-8") as f:
        data = yaml.safe_load(f)

    if data is None or "tags" not in data or not isinstance(data["tags"], list):
        return 0, 0, 0, False

    original_tags = data["tags"]
    new_tags, renamed, deleted, deduped = apply_mapping(original_tags, mapping)

    if renamed == 0 and deleted == 0 and deduped == 0:
        return 0, 0, 0, False

    if not dry_run:
        data["tags"] = new_tags

        # Use YAMLFormatter for consistent output
        formatted_data = formatter.format_document(data)
        formatted_yaml = formatter.format_dict(formatted_data)

        with open(file_path, "w", encoding="utf-8") as f:
            f.write(formatted_yaml)
            f.write("\n")

    return renamed, deleted, deduped, True


def main() -> None:
    """Run the tag consolidation across all YAML metadata files."""
    parser = argparse.ArgumentParser(
        description="Consolidate tags across YAML metadata files"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Report changes without writing files",
    )
    parser.add_argument(
        "--mapping",
        type=Path,
        default=MAPPING_FILE,
        help="Path to tag mapping JSON file",
    )
    args = parser.parse_args()

    # Load mapping
    if not args.mapping.exists():
        print(f"Error: Mapping file not found: {args.mapping}")
        print("Run: python scripts/build_tag_mapping.py")
        sys.exit(1)

    mapping = load_mapping(args.mapping)
    print(f"Loaded mapping: {len(mapping)} tag transformations")

    # Collect all YAML files
    yaml_files = sorted(METADATA_DIR.glob("**/*.yaml"))
    print(f"Found {len(yaml_files)} YAML files")

    if args.dry_run:
        print("\n=== DRY RUN — no files will be modified ===\n")

    # Process files
    formatter = YAMLFormatter()
    total_renames = 0
    total_deletes = 0
    total_dedupes = 0
    files_changed = 0

    for file_path in yaml_files:
        renamed, deleted, deduped, changed = process_file(
            file_path, mapping, formatter, dry_run=args.dry_run
        )

        if changed:
            files_changed += 1
            total_renames += renamed
            total_deletes += deleted
            total_dedupes += deduped

            if args.dry_run:
                rel_path = file_path.relative_to(PROJECT_ROOT)
                print(f"  {rel_path}: {renamed} renames, {deleted} deletes, {deduped} dedupes")

    # Count unique tags before and after
    before_tags = set()
    after_tags = set()
    for file_path in yaml_files:
        with open(file_path, encoding="utf-8") as f:
            data = yaml.safe_load(f)
        if data and isinstance(data.get("tags"), list):
            for tag in data["tags"]:
                if args.dry_run:
                    before_tags.add(tag)
                    after_tags.add(mapping.get(tag, tag))
                else:
                    after_tags.add(tag)

    # Summary
    print(f"\n{'=' * 50}")
    print(f"Summary:")
    print(f"  Files changed:    {files_changed} / {len(yaml_files)}")
    print(f"  Tags renamed:     {total_renames}")
    print(f"  Tags deleted:     {total_deletes}")
    print(f"  Deduplicates:     {total_dedupes}")
    if args.dry_run:
        print(f"  Unique tags before: {len(before_tags)}")
        print(f"  Unique tags after:  {len(after_tags)}")
        print(f"  Tags eliminated:    {len(before_tags) - len(after_tags)} ({(len(before_tags) - len(after_tags)) / len(before_tags) * 100:.1f}%)")
    else:
        print(f"  Unique tags now:  {len(after_tags)}")
    print(f"{'=' * 50}")


if __name__ == "__main__":
    main()
